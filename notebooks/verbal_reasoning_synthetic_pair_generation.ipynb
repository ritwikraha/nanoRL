{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwikraha/nanoRL/blob/experiments/notebooks/verbal_reasoning_synthetic_pair_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r51Bxhm0ZP9i"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "import random\n",
        "import json\n",
        "\n",
        "import time\n",
        "\n",
        "from datasets import Dataset\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "-GlAEFSO4DGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "W41WKB6ee-6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "yvZPFW1-4Kao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_preference_data(num_samples=2000):\n",
        "    topics = [\n",
        "        \"a logical analogy problem (e.g., 'Leaf is to Tree as Page is to X')\",\n",
        "        \"a short scenario requiring a logical deduction to find the outcome\",\n",
        "        \"identifying the unstated, underlying assumption in a given argument\",\n",
        "        \"determining the most logical cause for a specifically described effect\",\n",
        "        \"finding the word that doesn't belong in a group based on a shared category\",\n",
        "        \"evaluating a simple argument to pinpoint its primary logical flaw\",\n",
        "        \"drawing a single, valid conclusion from a short passage of text\",\n",
        "        \"completing a logical sequence of related words or concepts\",\n",
        "        \"identifying the specific relationship between two words (like cause/effect)\",\n",
        "        \"solving a simple syllogism to determine if the conclusion is valid\"\n",
        "    ]\n",
        "\n",
        "    generated_data = []\n",
        "    while len(generated_data) < num_samples:\n",
        "        try:\n",
        "            topic = random.choice(topics)\n",
        "\n",
        "            prompt_instruction = f\"Generate a single, clear question that is an example of the following verbal reasoning task: {topic}. Output nothing but the question itself, without any labels, formatting, or introductory text.\"\n",
        "            prompt = model.generate_content(prompt_instruction)\n",
        "            prompt = prompt.text.strip()\n",
        "\n",
        "            # prompt to generate the chosen/rejected pair with 'answer' and 'reasoning'\n",
        "            generation_prompt = f\"\"\"\\\n",
        "For the verbal reasoning question: \"{prompt}\"\n",
        "\n",
        "Please generate two distinct answers, each with an 'answer' and 'reasoning' field:\n",
        "1.  A logically sound and well-explained correct answer.\n",
        "2.  A plausible-sounding but logically flawed or incorrect answer.\n",
        "\n",
        "Format your response as a single, clean JSON object with two keys: \"chosen\" and \"rejected\".\n",
        "Each value (for \"chosen\" and \"rejected\") should itself be a JSON object with two keys: \"answer\" and \"reasoning\".\n",
        "\n",
        "Example:\n",
        "{{\n",
        "    \"chosen\": {{\n",
        "        \"answer\": \"Correct answer text.\",\n",
        "        \"reasoning\": \"Detailed explanation of why this answer is correct.\"\n",
        "    }},\n",
        "    \"rejected\": {{\n",
        "        \"answer\": \"Incorrect answer text.\",\n",
        "        \"reasoning\": \"Detailed explanation of why this answer is flawed or incorrect.\"\n",
        "    }}\n",
        "}}\\\n",
        "\"\"\"\n",
        "\n",
        "            response = model.generate_content(generation_prompt)\n",
        "            cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "\n",
        "            response_json = json.loads(cleaned_response)\n",
        "            if \"chosen\" in response_json and \"rejected\" in response_json:\n",
        "                # Ensure the 'chosen' and 'rejected' values are dictionaries with 'answer' and 'reasoning'\n",
        "                if isinstance(response_json[\"chosen\"], dict) and \\\n",
        "                   \"answer\" in response_json[\"chosen\"] and \"reasoning\" in response_json[\"chosen\"] and \\\n",
        "                   isinstance(response_json[\"rejected\"], dict) and \\\n",
        "                   \"answer\" in response_json[\"rejected\"] and \"reasoning\" in response_json[\"rejected\"]:\n",
        "\n",
        "                    generated_data.append({\n",
        "                        \"prompt\": prompt,\n",
        "                        \"chosen\": response_json[\"chosen\"],\n",
        "                        \"rejected\": response_json[\"rejected\"],\n",
        "                    })\n",
        "                    print(f\"SUCCESS: Generated sample {len(generated_data)}/{num_samples}\")\n",
        "                else:\n",
        "                    print(\"WARNING: Skipping sample due to 'chosen' or 'rejected' not having expected 'answer'/'reasoning' format.\")\n",
        "            else:\n",
        "                print(\"WARNING: Skipping sample due to missing 'chosen' or 'rejected' key.\")\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"WARNING: Skipping sample due to a JSON decoding error: {e}. Raw response: {cleaned_response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: An unexpected error occurred: {e}. Retrying in 5 seconds...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    if not generated_data:\n",
        "        print(\"INFO: No data was generated.\")\n",
        "        return \"\"\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame and then to a CSV string\n",
        "    return {key : [data[key] for data in generated_data] for key in [\"prompt\", \"chosen\", \"rejected\"]}"
      ],
      "metadata": {
        "id": "A550WoKc7B5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_dataset = generate_preference_data(num_samples=2)\n",
        "hf_ds = Dataset.from_dict(generated_dataset, split=\"train\")\n",
        "\n",
        "hf_ds.push_to_hub(\"ariG23498/reasoning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hx3GZsXb7nBA",
        "outputId": "e86db663-fc08-46dd-81bf-408c50263668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Generated sample 1/2\n",
            "SUCCESS: Generated sample 2/2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}